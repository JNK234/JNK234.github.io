<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <h2>Introduction</h2> <p>A large language model or LLM is a treasure trove and rich linguistic knowledge and information repository. Since these models are trained on petabytes of text data in different formats, these models possess a solid understanding of the patterns and the semantic details of the language it is pre-trained with, along with capabilities like multi-lingual understanding and contextual awareness. Therefore, specific techniques are developed to interact with the LLM so that we can extract the required information effectively. This process of engineering the input prompts to extract relevant and required answers is called Prompt Engineering. In this blog, let‚Äôs explore some of the best prompt engineering techniques. </p> <div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://images.unsplash.com/photo-1486312338219-ce68d2c6f44d?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHw4fHx0eXBlJTIwb24lMjBsYXB0b3B8ZW58MHx8fHwxNjk2OTM3MzY2fDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1080" data-component-name="Image2ToDOM" rel="external nofollow noopener"><div class="image2-inset"> <picture><source type="image/webp" srcset="https://images.unsplash.com/photo-1486312338219-ce68d2c6f44d?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHw4fHx0eXBlJTIwb24lMjBsYXB0b3B8ZW58MHx8fHwxNjk2OTM3MzY2fDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1080 424w, https://images.unsplash.com/photo-1486312338219-ce68d2c6f44d?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHw4fHx0eXBlJTIwb24lMjBsYXB0b3B8ZW58MHx8fHwxNjk2OTM3MzY2fDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1080 848w, https://images.unsplash.com/photo-1486312338219-ce68d2c6f44d?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHw4fHx0eXBlJTIwb24lMjBsYXB0b3B8ZW58MHx8fHwxNjk2OTM3MzY2fDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1080 1272w, https://images.unsplash.com/photo-1486312338219-ce68d2c6f44d?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHw4fHx0eXBlJTIwb24lMjBsYXB0b3B8ZW58MHx8fHwxNjk2OTM3MzY2fDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1080 1456w" sizes="100vw"></source><img src="https://images.unsplash.com/photo-1486312338219-ce68d2c6f44d?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHw4fHx0eXBlJTIwb24lMjBsYXB0b3B8ZW58MHx8fHwxNjk2OTM3MzY2fDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1080" width="4076" height="2712" data-attrs='{"src":"https://images.unsplash.com/photo-1486312338219-ce68d2c6f44d?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHw4fHx0eXBlJTIwb24lMjBsYXB0b3B8ZW58MHx8fHwxNjk2OTM3MzY2fDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1080","srcNoWatermark":null,"fullscreen":null,"imageSize":null,"height":2712,"width":4076,"resizeWidth":null,"bytes":null,"alt":"person using MacBook Pro","title":null,"type":"image/jpg","href":null,"belowTheFold":false,"topImage":true,"internalRedirect":null,"isProcessing":false,"align":null,"offset":false}' class="sizing-normal" alt="person using MacBook Pro" title="person using MacBook Pro" srcset="https://images.unsplash.com/photo-1486312338219-ce68d2c6f44d?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHw4fHx0eXBlJTIwb24lMjBsYXB0b3B8ZW58MHx8fHwxNjk2OTM3MzY2fDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1080 424w, https://images.unsplash.com/photo-1486312338219-ce68d2c6f44d?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHw4fHx0eXBlJTIwb24lMjBsYXB0b3B8ZW58MHx8fHwxNjk2OTM3MzY2fDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1080 848w, https://images.unsplash.com/photo-1486312338219-ce68d2c6f44d?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHw4fHx0eXBlJTIwb24lMjBsYXB0b3B8ZW58MHx8fHwxNjk2OTM3MzY2fDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1080 1272w, https://images.unsplash.com/photo-1486312338219-ce68d2c6f44d?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHw4fHx0eXBlJTIwb24lMjBsYXB0b3B8ZW58MHx8fHwxNjk2OTM3MzY2fDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1080 1456w" sizes="100vw" fetchpriority="high"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"> <div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewbox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div> <div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewbox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div> </div></div> </div></a><figcaption class="image-caption">Photo by <a href="https://unsplash.com/@glenncarstenspeters" rel="external nofollow noopener" target="_blank">Glenn Carstens-Peters</a> on <a href="https://unsplash.com" rel="external nofollow noopener" target="_blank">Unsplash</a></figcaption></figure></div> <h2>Prompt Engineering: Getting Started</h2> <p><strong>Prompt Engineering</strong> is the process of designing input prompts and queries used to interact with Large language models like chatbots or domain-specific fine-tuned models. The main goal of prompt engineering is to elicit desired responses or behaviours from the LLM. Before we delve into different techniques of prompt engineering, let‚Äôs revisit the basic mechanism of LLM Inference. </p> <p>Every model takes in a text called <strong>prompt</strong> as input. The LLM generates the required text called <strong>completion</strong> based on the input prompt. The length of the generated text or completion depends upon the context window of the LLM. <strong>The context window is the total number of tokens (or words) </strong>the model can process at a time. The context window of the model can be represented as follows,</p> <blockquote><p>Context window of LLM = Length of input prompt + Length of completion </p></blockquote> <p>Usually, the context window of LLMs is <strong>fixed</strong> up to 1000 or 2000 tokens, so we should define the input prompt effectively so that the LLM has enough context window to generate the required completion. </p> <p>Let‚Äôs explore a few prompt engineering techniques for effective LLM inference.</p> <h2>Prompt Engineering Techniques</h2> <p>Some of the most widely used prompt engineering techniques are:</p> <ul> <li><p>Zero-Shot learning</p></li> <li><p>In-Context Learning: One-shot and Few-shot learning. </p></li> <li><p>Chain of thought prompting </p></li> </ul> <p>Let‚Äôs explore each of them in more detail. </p> <h3>Zero-Shot Learning </h3> <p><strong>Zero-shot learning</strong> or prompting is based on the principle that LLMs like GPT-3 and GPT-4 are finetuned to follow instructions and are usually trained on large amounts of data. Therefore, these LLMs can perform tasks ‚Äúzero-shot‚Äù or tasks without additional fine-tuning. </p> <p>For example, consider providing the following prompt to LLMs like GPT-3 or ChatGPT,</p> <pre><code><strong>Prompt:</strong> 
Detect the sentence's sentiment as Positive, Negative or Neutral: 
I love the scenery of the place! 

Sentiment: 

<strong>Output:</strong> 
Sentiment: Positive</code></pre> <p>We can see that the model correctly identifies the sentiment of the sentence and completes the prompt with the option <strong>Positive. </strong>This capability of the large language model to perform inference tasks without additional fine-tuning and just using the knowledge learnt during model training is called <strong>zero-shot inference</strong>. Zero-shot inference best works for larger models, usually multi-billion parameter models like GPT-4, LLama, Falcon, etc. </p> <p>But zero-shot inference is lacking in generating coherent completions when it comes to prompts or tasks that require more context, or it is a task not usually the LLM was trained upon directly. This is where we can use In-context learning techniques to customize the model generation by specifying additional context in the input prompt. </p> <h3>In-Context Learning</h3> <p>In-context learning refers to learning from the context provided in the input prompt. One-shot learning and Few-shot learning are some techniques under In-context learning. </p> <p>One-shot Learning or prompting enables the LLM to perform better by providing additional context in the input prompt. This is done by designing the prompt by including one example of the complex task that needs to be performed. Consider the following example of performing One-shot inference,</p> <pre><code><strong>Prompt:</strong>
Classify this review: I loved the cast and the story !
Sentiment: Positive 

Classify this review: I hated the performance of villian !
Sentiment:

<strong>Output:</strong>
Sentiment: Negative</code></pre> <p>In the above example, we have provided an example of the prompt as well as the completion of a sentiment analysis task. Then, we have provided another example for the model to perform inference. By observing the context and structure of output provided in the initial prompt, the model generates completion for the later prompt in the required format. </p> <p>This prompting method can be further improved by including multiple examples of tasks in the context. This prompting method is called <strong>Few-shot learning</strong>. Few-shot learning includes multiple examples of that complex task to be performed in the context of the prompt. Then, the model will generate the output based on the patterns and observations from the input prompt‚Äôs context. </p> <p>Let‚Äôs explore another interesting prompting technique to improve text generation quality.</p> <h3>Chain-of-Thought Prompting </h3> <p>Chain-of-thought prompting technique enables complex reasoning capabilities in LLMs by providing intermediate reasoning steps in the context of the input prompt. This can be further improved by combining the few-shot prompting technique to get better results on a highly complex task involving much reasoning before responding. </p> <p>To better illustrate the capabilities of Chain-of-thought prompting, consider the following example, </p> <div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/$s_!bCMT!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F66b20765-42bf-4162-828e-3a9b0531ba1f_2082x962.png" data-component-name="Image2ToDOM" rel="external nofollow noopener"><div class="image2-inset"> <picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!bCMT!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F66b20765-42bf-4162-828e-3a9b0531ba1f_2082x962.png 424w, https://substackcdn.com/image/fetch/$s_!bCMT!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F66b20765-42bf-4162-828e-3a9b0531ba1f_2082x962.png 848w, https://substackcdn.com/image/fetch/$s_!bCMT!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F66b20765-42bf-4162-828e-3a9b0531ba1f_2082x962.png 1272w, https://substackcdn.com/image/fetch/$s_!bCMT!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F66b20765-42bf-4162-828e-3a9b0531ba1f_2082x962.png 1456w" sizes="100vw"></source><img src="https://substackcdn.com/image/fetch/$s_!bCMT!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F66b20765-42bf-4162-828e-3a9b0531ba1f_2082x962.png" width="1456" height="673" data-attrs='{"src":"https://substack-post-media.s3.amazonaws.com/public/images/66b20765-42bf-4162-828e-3a9b0531ba1f_2082x962.png","srcNoWatermark":null,"fullscreen":null,"imageSize":null,"height":673,"width":1456,"resizeWidth":null,"bytes":271966,"alt":null,"title":null,"type":"image/png","href":null,"belowTheFold":true,"topImage":false,"internalRedirect":null,"isProcessing":false,"align":null,"offset":false}' class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/$s_!bCMT!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F66b20765-42bf-4162-828e-3a9b0531ba1f_2082x962.png 424w, https://substackcdn.com/image/fetch/$s_!bCMT!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F66b20765-42bf-4162-828e-3a9b0531ba1f_2082x962.png 848w, https://substackcdn.com/image/fetch/$s_!bCMT!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F66b20765-42bf-4162-828e-3a9b0531ba1f_2082x962.png 1272w, https://substackcdn.com/image/fetch/$s_!bCMT!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F66b20765-42bf-4162-828e-3a9b0531ba1f_2082x962.png 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"> <div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewbox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div> <div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewbox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div> </div></div> </div></a><figcaption class="image-caption">Source: https://arxiv.org/abs/2201.11903</figcaption></figure></div> <p>We can observe that according to the above example, the model was able to answer the question better when additional reasoning was provided with the correct answer. This prompting technique works best when coupled with few-shot learning. </p> <h2>Beyond Prompt Engineering?</h2> <p>Using the above prompt engineering techniques, LLMs can generate coherent and accurate completions for a wide variety of tasks. But sometimes, LLMs tend to hallucinate while generating completion for a prompt or might not produce completions of good quality even after providing multiple examples in few-shot prompting. </p> <p>In this scenario, task-based fine-tuning of large language models is the best way to handle uncertainty in text generation. The pre-trained model is fine-tuned in this approach with a prompt-based task dataset created for the specific task. This will help the model adapt to the prompt structure easily compared to few-shot learning. </p> <h2>Conclusion</h2> <p>Large language models with billions of parameters trained with petabytes of data will have excellent natural language processing and understanding capabilities. These LLMs will also have a large memory to process and generate text related to any topic. However, this indefinite potential of knowledge and information possessed by LLMs can be utilized by effective querying techniques called prompt engineering. As and when the sizes of LLMs increase, it is necessary for us to use these prompt engineering techniques to query better and mine the knowledge from LLMs effectively.</p> <h2>Summary</h2> <p>To summarise, </p> <ul> <li><p>Large language models with multiple billions of parameters consist of rich representation and understanding of knowledge and information. </p></li> <li><p>Prompt Engineering is the process of designing prompts to input to LLMs to extract required and meaningful completions. </p></li> <li><p>Some popular prompt engineering techniques are Zero-shot prompting, In-context learning, and Chain-of-thought prompting.</p></li> <li><p>Zero-shot prompting includes the task within the input prompt to be performed, i.e. for the model to generate completion. </p></li> <li><p>In-context learning includes defining the context of the problem to be resolved in the input prompt. This can be done by providing one (one-shot learning) or more examples (few-shot learning) in the input prompt. </p></li> <li><p>Chain-of-thought learning improves the completion quality by including the intermediate reasoning steps and the examples in the input prompt. This improves the model's reasoning capability and helps generate more coherent completion.</p></li> <li><p>If the quality of the completion generated by the model doesn‚Äôt improve even after providing additional examples, i.e.few-shot prompting, model fine-tuning must be performed. </p></li> </ul> <p>Thanks for reading! </p> <div><hr></div> <div class="subscription-widget-wrap-editor" data-attrs='{"url":"https://neuraforge.substack.com/subscribe?","text":"Subscribe","language":"en"}' data-component-name="SubscribeWidgetToDOM"><div class="subscription-widget show-subscribe"> <div class="preamble"><p class="cta-caption">Step into a world of discovery with our technical newsletter. Delve deep into applied Machine Learning, Generative AI and advanced Deep Learning concepts as we unravel fundamental concepts and unveil the latest research trends. Embark on this exhilarating journey of learning and growth with us by subscribing to the newsletter! üöÄü§ñ</p></div> <form class="subscription-widget-subscribe"> <input type="email" class="email-input" name="email" placeholder="Type your email‚Ä¶" tabindex="-1"><input type="submit" class="button primary" value="Subscribe"><div class="fake-input-wrapper"> <div class="fake-input"></div> <div class="fake-button"></div> </div> </form> </div></div> <p></p> <p></p> <p></p> </body></html>