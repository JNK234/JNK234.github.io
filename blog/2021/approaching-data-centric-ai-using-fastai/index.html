<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*1_Do5p1u9-VIke44y5xdTQ.jpeg"><figcaption>Photo by <a href="https://unsplash.com/@hjrc33?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="external nofollow noopener" target="_blank">Héctor J. Rivas</a> on <a href="https://unsplash.com/s/photos/images?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="external nofollow noopener" target="_blank">Unsplash</a></figcaption></figure> <p>This blog post is part of the 100-days of Deep Learning challenge. I have started this challenge by reading the book <strong><em>“Deep Learning for Coders with fastai &amp; PyTorch”</em></strong> by Jeremy Howard and Sylvain Gugger, to learn about the fastai library and its applications in deep learning.</p> <p>Fastai library is a deep learning library that adds higher-level functionalities on top of PyTorch. So this is a perfect choice of the library for quick prototyping and model building on different datasets as well as utilising the flexibility and speed of PyTorch.</p> <p>In this blog post, let us discuss the data-centric approach of training deep learning models. Data-centric AI is based on the concept of systematically enhancing the datasets over the course of model development to improve the model metrics. This approach is usually overlooked and data collection and cleaning has not been the most favourite task.</p> <blockquote>“The model and the code for many applications are basically a solved problem. Now that the models have advanced to a certain point, we got to make the data work as well” — Andrew Ng</blockquote> <p>Let’s train an image classifier pipeline from scratch i.e. from gathering data to training the model using the fastai library thereby exploring the potential of the data-centric model training approach.</p> <h3>Gathering the Data</h3> <p>Let’s train a bear detector i.e. it will discriminate between three types of bears: grizzly, black and teddy bear. To obtain the dataset, let’s use the <strong>jmd_imagescraper </strong>library. This is an image scraping library for creating datasets. It uses the DuckDuckGo for image scraping, hence you can verify the images being downloaded by searching in DuckDuckGo.</p> <p>Let’s install the required libraries,</p> <iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/715142e118c431359a66fa53b99276b3/href" rel="external nofollow noopener" target="_blank">https://medium.com/media/715142e118c431359a66fa53b99276b3/href</a></iframe> <p>Now let’s import the fastai and jmd_imagescraper library,</p> <iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/0fe22a684a2647ab76093c4577bd5d9e/href" rel="external nofollow noopener" target="_blank">https://medium.com/media/0fe22a684a2647ab76093c4577bd5d9e/href</a></iframe> <p>We have to download the images corresponding to 3 classes i.e. grizzly, black and teddy bear. To download the dataset, we have to pass the path to download, name of the folder, search string and number of results to be downloaded as arguments to download the dataset.</p> <iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/c709b8f367c7642479ccece1f20a9987/href" rel="external nofollow noopener" target="_blank">https://medium.com/media/c709b8f367c7642479ccece1f20a9987/href</a></iframe> <p>You can check the images downloaded in the Data folder. Since we have downloaded the data from the internet, there are chances that it might be corrupted, so let’s verify and delete the corrupted one.</p> <iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/9034b090f7e4eb83d007ce79a149d4a2/href" rel="external nofollow noopener" target="_blank">https://medium.com/media/9034b090f7e4eb83d007ce79a149d4a2/href</a></iframe> <p>Fastai provides a variety of util functions which makes it easy to work with. The get_image_files is a fastai function that returns an L object containing the paths to all images. The verify_images function is used to check for corrupted image files in the list.</p> <p>Since now we have our dataset ready let’s proceed to prepare data for model training.</p> <h3>From Data to DataLoaders</h3> <p>In PyTorch, DataLoader is a class that takes the dataset and returns an iterable which can be passed to the model for training in batches. Similarly, the DataLoaders class in fastai takes DataLoader objects which we pass and makes them available for training and validation.</p> <p>To convert our downloaded data into DataLoaders in fastai, the most efficient way is to use the DataBlock API. Using this API, we can easily customize and control every stage in preparing the dataloaders. Let’s define the DataBlock object for the above dataset.</p> <iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/fedfd4ca94e002ac296a3fffc10c54e0/href" rel="external nofollow noopener" target="_blank">https://medium.com/media/fedfd4ca94e002ac296a3fffc10c54e0/href</a></iframe> <p>Let’s look at each of the arguments and how it is used,</p> <ul> <li> <strong>blocks</strong>: This defines the types of independent and dependent variables that we are providing to model i.e in our case we are providing an image and a category hence <em>ImageBlock</em> and <em>CategoryBlock</em>.</li> <li> <strong>get_items</strong>: This defines how to get the list of items. <em>get_image_files</em> is a fastai function that accepts the path as an argument and returns the list of all images in that path recursively.</li> <li> <strong>get_y</strong>: This defines how to identify the dependent variables/labels from items retrieved using the <em>get_items </em>function<em>. </em><em>parent_label </em>is a fastai function that simply returns the name of the folder a file is in.</li> <li> <strong>splitter</strong>: Since we have got our data and labels, we need to specify how to split the data using this argument. <em>RandomSplitter</em> splits the dataset into training and validation sets randomly but uses a seed to make sure that the model gets the same data for training and validation for every epoch.</li> <li> <strong>item_tfms</strong>: As we are providing multiple image samples as a batch at a time, we need to resize the images. Hence we use the <em>Resize() </em>method on each image as an argument to item_tfms.</li> </ul> <p>As of now, we have defined the basic datablock object. Now let’s use it to create dataloaders from the dataset.</p> <iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/1d59e1316f1bd934d3e8d331c0ddf159/href" rel="external nofollow noopener" target="_blank">https://medium.com/media/1d59e1316f1bd934d3e8d331c0ddf159/href</a></iframe> <p>Using the <em>show_batch() </em>method we can visualize a few samples present in the dataset. We can expect a similar output as follows,</p> <figure><img alt="List of images in dataset along with the labels." src="https://cdn-images-1.medium.com/max/1024/1*Yeiq1S_eAVSWiK2oFshnNg.png"></figure> <p>We can see that we have easily created dataloaders and from raw data without much hassle using DataBlock API.</p> <p>Now we have the data ready in the format required for model training. Before we delve into training, let’s explore another important part of model pipeline data augmentation.</p> <h3>Data Augmentation</h3> <p>Data augmentation refers to creating random variations of samples such that they appear different but do not change the meaning of the image. This is one of the ways to ensure that model is not memorizing the input images but learning about the patterns in the data. Let’s look at some of the most commonly used augmentation techniques.</p> <ul><li>Using <em>RandomResizedCrop</em> instead of <em>Resize</em> as item transform because this transforms not only size but also the orientation and scale of the image randomly. Let’s look at how it is done,</li></ul> <iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/56882b1e91685ccbbc1a347931d8a3db/href" rel="external nofollow noopener" target="_blank">https://medium.com/media/56882b1e91685ccbbc1a347931d8a3db/href</a></iframe> <p>We can create a new datablock object using the <em>new </em>method on the existing datablock and passing the new item and batch transform. The RandomResizedCrop method accepts the <em>min_scale </em>argument which determines how much of the image to select at a minimum each time. Finally, by setting unique=True in <em>show_batch</em> function we can have the same image repeated with different versions of <em>RandomResizedCrop </em>transforms<em>.</em></p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*Ji9hElDpyYdKwqrk6pmfiQ.png"></figure> <ul><li>Using <em>aug_transforms </em>function on a batch of images. This is a fastai function that applies multiple augmentations like flipping, changing brightness, contrast etc. This can be applied to a batch of images as all the images will be of the same size.</li></ul> <iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/4eafcf8dae513861714af6620eb77c2a/href" rel="external nofollow noopener" target="_blank">https://medium.com/media/4eafcf8dae513861714af6620eb77c2a/href</a></iframe> <p>You can see a similar output as follows,</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*iCoUWPQ1DWcdfD6XxkFWiw.png"></figure> <p>Now since we have seen some ways to perform data augmentation let’s combine the methods and get the final dataloaders.</p> <iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/bab26f83e4ad8fb976c4d180485b2392/href" rel="external nofollow noopener" target="_blank">https://medium.com/media/bab26f83e4ad8fb976c4d180485b2392/href</a></iframe> <p>Let’s dive into creating and training the model…</p> <h3>Training Your Model</h3> <p>Now coming to the fun part… Since we don’t have a lot of data for our problem, training a model with high accuracy will be difficult without running into the problem of over-fitting. Unless we are using a technique called <strong>transfer learning</strong>.</p> <p>Transfer learning is a training method where we use a pre-trained model ( i.e. a model that has been trained previously on different tasks ) and fine-tune with our dataset. This method has proved to achieve amazing results even with less training data and by taking less time. Now let’s see how it is done in fastai,</p> <iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/f5ccdf0fdb6b705657f730f118778116/href" rel="external nofollow noopener" target="_blank">https://medium.com/media/f5ccdf0fdb6b705657f730f118778116/href</a></iframe> <p>After training for 4 epochs we can see that the accuracy of the model is closer to 95% and that is pretty impressive.</p> <p>Now let’s see the confusion matrix to make more sense of the model performance.</p> <iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/376a565dbc9afe6cf491576dbd95424d/href" rel="external nofollow noopener" target="_blank">https://medium.com/media/376a565dbc9afe6cf491576dbd95424d/href</a></iframe> <figure><img alt="" src="https://cdn-images-1.medium.com/max/716/1*B_hcX9eVXq5FMwwJLpvjMg.png"></figure> <p>From the confusion matrix, we can observe that our model was able to correctly classify almost all images.</p> <p>In the below table, we can see the images that the model has misclassified with maximum loss. We can see that the first image belongs to the black Bear class but our model has predicted it as Grizzly Bear.</p> <p>But if we observe the bear image, it resembles more like a grizzly bear than a black bear. So there has been some mess up while labelling the image. (Since these are downloaded directly from DuckDuckGo without our interference)</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*GrWYocBzqooDWupdJM7nsA.png"></figure> <h3>Data Cleaning through Model</h3> <p>Now since our model is trained, let’s now use the data-centric approach to improve the model. This can be done by examining the data used for training and validation i.e. check if images are labelled correctly and then update it with the correct label.</p> <p>Intuitively, data cleaning is done before model training. But as we have seen above, the model helps us to identify issues in the data. So to perform data cleaning, fastai provides a handy GUI that allows us to choose a category or delete samples from both training and validation datasets.</p> <iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/5bfee894877da32c42568dedb129e8f0/href" rel="external nofollow noopener" target="_blank">https://medium.com/media/5bfee894877da32c42568dedb129e8f0/href</a></iframe> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*nSXyKdIlSuqSX9Nxs9x36w.png"></figure> <p>We will get the above GUI which displays images with the highest loss in order (i.e. what model think it is not right). Now we can choose the category of the image in the dropdown menu and then perform changes using the following code.</p> <iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/ee01673eacb0ee8040f492c3460e038b/href" rel="external nofollow noopener" target="_blank">https://medium.com/media/ee01673eacb0ee8040f492c3460e038b/href</a></iframe> <p>Now we can clean the data easily and again train the model. We will be able to see that the model performance will have improved far better (almost 99~100% accuracy).</p> <p>The Data-Centric Approach of model training and transfer learning helps us to train models on real-world datasets and achieve state-of-the-art results. Hence there is a need to shift our focus from model-centric AI to data-centric AI and explore the potential of MLOps.</p> <p>Thank you !!</p> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=6099c3d3e0e1" width="1" height="1" alt=""></p> </body></html>