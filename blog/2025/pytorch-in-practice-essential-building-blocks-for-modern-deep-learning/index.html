<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <h4>From Tensors to Neural Networks: Understanding Core Components</h4> <h3>Introduction</h3> <p>As deep learning continues to advance artificial intelligence applications, PyTorch has established itself as a fundamental framework powering everything from computer vision systems to large language models. Originally developed by Meta’s AI Research lab, PyTorch combines Python’s flexibility with deep learning capabilities through a powerful, intuitive interface.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*MjgGftC7-d5x2mD7"><figcaption>Photo by <a href="https://neuraforge.substack.com/p/true" rel="external nofollow noopener" target="_blank">Iker Urteaga</a> on <a href="https://unsplash.com/" rel="external nofollow noopener" target="_blank">Unsplash</a></figcaption></figure> <h4>Core Components of PyTorch</h4> <p>PyTorch’s architecture rests on three key components that work together to enable efficient deep learning development:</p> <ol><li><strong>Dynamic Tensor Library</strong></li></ol> <ul> <li>Extends NumPy’s array programming capabilities</li> <li>Provides seamless CPU and GPU acceleration</li> <li>Implements efficient mathematical operations for deep learning computations</li> </ul> <p>2. <strong>Automatic Differentiation Engine (Autograd)</strong></p> <ul> <li>Computes gradients automatically through computational graphs</li> <li>Manages backpropagation for neural network training</li> </ul> <p>3. <strong>Deep Learning Framework</strong></p> <ul> <li>Delivers modular neural network components</li> <li>Implements optimized loss functions and optimizers</li> </ul> <h3>Getting Started with PyTorch</h3> <h4>Installation and Setup</h4> <p>PyTorch can be installed directly using pip, Python’s package installer:</p> <pre>pip install torch</pre> <p>However, for optimal performance, it’s recommended to install the version specifically compatible with your system’s hardware. Visit <a href="https://pytorch.org/" rel="external nofollow noopener" target="_blank">pytorch.org</a> to get the appropriate installation command based on your:</p> <ul> <li>Operating system</li> <li>Package manager preference (pip/conda)</li> <li>CUDA version (for GPU support)</li> <li>Python version</li> </ul> <h4>GPU Support and Compatibility</h4> <p>PyTorch seamlessly integrates with NVIDIA GPUs through CUDA. To verify GPU availability in your environment:</p> <pre><br># Check GPU availability<br>gpu_available = torch.cuda.is_available()<br>print(f"GPU Available: {gpu_available}")<br><br># Get GPU device count if available<br>if gpu_available:<br>    print(f"Number of GPUs: {torch.cuda.device_count()}")</pre> <p>If a GPU is detected, you can move tensors and models to GPU memory using:</p> <pre># Create a tensor<br>tensor = torch.tensor([1.0, 2.0, 3.0])<br><br># Move to GPU if available<br>device = "cuda" if torch.cuda.is_available() else "cpu"<br>tensor = tensor.to(device)</pre> <h4>Apple Silicon Support</h4> <p>For users with Apple M1/M2/M3 chips, PyTorch provides acceleration through the Metal Performance Shaders (MPS) backend. Verify MPS availability:</p> <pre><br># Check MPS (Metal Performance Shaders) availability<br>mps_available = torch.backends.mps.is_available()<br>print(f"MPS Available: {mps_available}")<br><br># If MPS is available, you can use it as device<br>if mps_available:<br>    device = torch.device("mps")<br>    # Move tensors/models to MPS device<br>    tensor = tensor.to(device)</pre> <p>For ease of usage, I recommend using <a href="https://colab.research.google.com/" rel="external nofollow noopener" target="_blank">Google Colab</a> i.e. a popular jupyter notebook–like environment, which provides time-limited access to GPUs.</p> <h3>Understanding Tensors</h3> <h4>What Are Tensors?</h4> <p>Tensors are mathematical objects that generalize vectors and matrices to higher dimensions. In PyTorch, tensors serve as fundamental data containers that hold and process multi-dimensional arrays of numerical values. These containers enable efficient computation and automatic differentiation, making them essential for deep learning operations. PyTorch tensors are similar to Numpy arrays in basic sense.</p> <h4>Scalers, Vectors, Matrices and Tensors</h4> <figure><img alt="" src="https://cdn-images-1.medium.com/max/800/0*HVGh8DKM7kouoN-m.png"></figure> <p>As mentioned earlier, PyTorch tensors are data containers for array-like structures. A scalar is a zero-dimensional tensor (for instance, just a number), a vector is a one-dimensional tensor, and a matrix is a two-dimensional tensor. There is no specific term for higher-dimensional tensors, so we typically refer to a three-dimensional tensor as just a 3D tensor, and so forth. We can create objects of PyTorch’s `Tensor` class using the `torch.tensor` function as shown in the following listing.</p> <pre>import torch<br><br># Scalar (0-dimensional tensor)<br>scalar = torch.tensor(1)     <br><br># Vector (1-dimensional tensor)<br>vector = torch.tensor([1, 2, 3])    <br><br># Matrix (2-dimensional tensor)<br>matrix = torch.tensor([[1, 2], <br>                      [3, 4]])     <br><br># 3-dimensional tensor<br>tensor3d = torch.tensor([[[1, 2], [3, 4]], <br>                        [[5, 6], [7, 8]]])</pre> <p>Each tensor type maintains its specific dimensionality, accessible through the <strong>.shape</strong> attribute:</p> <pre>print(f"Scalar shape: {scalar.shape}")      # torch.Size([])<br>print(f"Vector shape: {vector.shape}")      # torch.Size([3])<br>print(f"Matrix shape: {matrix.shape}")      # torch.Size([2, 2])<br>print(f"3D tensor shape: {tensor3d.shape}") # torch.Size([2, 2, 2])</pre> <h4>Tensor Data Types and Precision</h4> <p>PyTorch supports various data types with different precision levels, optimized for different computational needs:</p> <p>Some of the common torch datatypes available with torch are float32, float64, float16, bfloat16, int8, uint8, int16, int32, int64.</p> <p>The choice of precision impacts both memory usage and computational efficiency:</p> <ul> <li>float32: Standard for most deep learning tasks</li> <li>float16: Reduced precision, useful for memory optimization</li> <li>bfloat16: Brain Floating Point, balances precision and range</li> </ul> <h4>Floating Data Types</h4> <p>PyTorch supports various floating-point precisions for tensors, each serving different computational needs:</p> <ul> <li>torch.float32 (default): 32-bit precision offering 6-9 decimal places, optimal for most deep learning tasks</li> <li>torch.float64: 64-bit double precision with 15-17 decimal places, suitable for high-precision numerical computations</li> <li>torch.float16: 16-bit half precision with 3-4 decimal places, useful for memory-efficient operations</li> <li>torch.bfloat16: Brain floating point format with 2-3 decimal precision, balancing range and precision</li> </ul> <pre>import torch<br><br>float32_tensor = torch.tensor([1.0, 2.0], dtype=torch.float32)  <br>float64_tensor = torch.tensor([1.0, 2.0], dtype=torch.float64)  <br>float16_tensor = torch.tensor([1.0, 2.0], dtype=torch.float16)  <br>bfloat16_tensor = torch.tensor([1.0, 2.0], dtype=torch.bfloat16)</pre> <h4>Integer Types</h4> <p>PyTorch supports various integer data types, each with specific memory allocations and value ranges:</p> <ul> <li>int8: 8-bit signed integers (-128 to 127)</li> <li>uint8: 8-bit unsigned integers (0 to 255)</li> <li>int16: 16-bit signed integers (-32768 to 32767)</li> <li>int32: 32-bit signed integers (-2^31 to 2^31-1)</li> <li>int64: 64-bit signed integers (-2^63 to 2^63-1), default integer type in PyTorch</li> </ul> <pre>int8_tensor = torch.tensor([1, 2], dtype=torch.int8)     <br>uint8_tensor = torch.tensor([1, 2], dtype=torch.uint8)   <br>int16_tensor = torch.tensor([1, 2], dtype=torch.int16)   <br>int32_tensor = torch.tensor([1, 2], dtype=torch.int32)   <br>int64_tensor = torch.tensor([1, 2], dtype=torch.int64)</pre> <h4>Datatype Conversion</h4> <p>We can convert tensors from one datatype to another using the .to method.</p> <pre># Converting between data types<br>tensor = torch.tensor([1, 2, 3])<br><br>float_tensor = tensor.to(torch.float32) # Convert from int64 to float32<br>int_tensor = tensor.to(torch.int32)     # Convert from float32 to int32</pre> <h3>Common Tensor Operations</h3> <p>PyTorch provides several fundamental tensor operations essential for deep learning computations. Here are the key operations with their implementations and specific use cases.</p> <h4>1. Tensor Creation and Shape Manipulation</h4> <p>Creating tensors and understanding their shape are fundamental operations in PyTorch:</p> <pre>import torch<br><br># Create 2D tensor<br>tensor2d = torch.tensor([[1, 2, 3], <br>                        [4, 5, 6]])<br><br># Check tensor shape<br>shape = tensor2d.shape  <br># Returns: torch.Size([2, 3])</pre> <p>For the above tensor, the shape if 2 x 3 i.e. 2 rows and 3 columns. We can change the shape of the array by maintaining the total size of the array using reshape method.</p> <h4>2. Reshaping Operations</h4> <p>PyTorch offers two methods for tensor reshaping:</p> <pre># Reshape tensor from (2,3) to (3,2)<br>reshaped_tensor = tensor2d.reshape(3, 2)<br><br># Alternative using view<br>viewed_tensor = tensor2d.view(3, 2)</pre> <p><strong>Technical Note</strong>: .view() and .reshape() differ in memory handling:</p> <ul> <li>.view(): Requires contiguous memory layout</li> <li>.reshape(): Works with any memory layout, performs copy if necessary</li> </ul> <h4>3. Matrix Operations</h4> <p>PyTorch implements efficient matrix operations essential for linear algebra computations:</p> <pre># Transpose operation<br>transposed = tensor2d.T<br><br># Matrix multiplication methods<br>result1 = tensor2d.matmul(tensor2d.T)  # Using matmul<br>result2 = tensor2d @ tensor2d.T        # Using @ operator</pre> <p>Output shapes for a 2x3 input tensor:</p> <ul> <li>Transpose: 3x2</li> <li>Matrix multiplication with transpose: 2x2</li> </ul> <p>These operations form the foundation for neural network computations and linear algebra operations in deep learning models. For an exhaustive list of tensor operations, refer to the <a href="https://pytorch.org/docs/stable/tensors.html" rel="external nofollow noopener" target="_blank">PyTorch documentation</a>.</p> <h3>Automatic Differentiation</h3> <h4>Understanding Computational Graphs</h4> <p>PyTorch builds computational graphs that track operations performed on tensors. These graphs enable automatic differentiation through the autogradsystem, making gradient computation efficient and programmatic.</p> <p>A computational graph is a directed graph that allows us to express and visualize mathematical expressions. In the context of deep learning, a computation graph lays out the sequence of calculations needed to compute the output of a neural network — we will need this to compute the required gradients for backpropagation, the main training algorithm for neural networks.</p> <p>Consider the following example of a single layer neural network performing logistic regression with single weight and bias.</p> <pre>import torch<br>import torch.nn.functional as F<br><br># Initialize inputs and parameters<br>y = torch.tensor([1.0])           # Target<br>x1 = torch.tensor([1.1])          # Input<br>w1 = torch.tensor([2.2], <br>                  requires_grad=True)  # Weight<br>b = torch.tensor([0.0], <br>                 requires_grad=True)   # Bias<br><br># Forward pass computation<br>z = x1 * w1 + b                   # Linear computation<br>a = torch.sigmoid(z)              # Activation<br>loss = F.binary_cross_entropy(a, y)    # Loss computation</pre> <p>We have used the torch.nn.functional module from torch which provides many utility functions like loss functions, activations etc required to write and train deep neural networks.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*e_agaazNkZeE48Ie"></figure> <p><em>Source: </em><a href="https://github.com/rasbt/LLMs-from-scratch/tree/main" rel="external nofollow noopener" target="_blank"><em>LLMs from Scratch</em></a></p> <h4>Gradient Computation with Autograd</h4> <p>To train the above model, we have to compute the gradients of loss w.r.t w1 and bwhich will be further used to update the existing weights iteratively. This is where PyTorch makes our life easier by automatically calculating them using the autograd engine.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*cA24CuRSLTFFncr7"></figure> <p><em>Source: </em><a href="https://github.com/rasbt/LLMs-from-scratch/tree/main" rel="external nofollow noopener" target="_blank"><em>LLMs from Scratch</em></a></p> <p>PyTorch’s autograd system automatically computes gradients for all tensors with requires_grad=True. Here's how to compute gradients:</p> <pre>from torch.autograd import grad<br><br># Manual gradient computation<br>grad_L_w1 = grad(loss, w1, retain_graph=True)<br>grad_L_b = grad(loss, b, retain_graph=True)<br><br># Alternative using backward()<br>loss.backward()<br>print(w1.grad)    # Access gradient for w1<br>print(b.grad)     # Access gradient for b</pre> <p><strong>Technical Note</strong>: When using backward():</p> <ul> <li>Gradients accumulate by default</li> <li>Use zero_grad() before each backward pass in training loops</li> <li>retain_graph=True allows multiple backward passes</li> </ul> <p>The grad function is used to get gradients manually and it is useful for debugging and demonstration purposes. Using the backward() function automatically calculates for all the tensors which has requires_grad=True set and gradients will be stored inside .grad property.</p> <h3>Building Neural Networks with PyTorch</h3> <p>Next, we focus on PyTorch as a library for implementing deep neural networks. While our previous example demonstrated a single neuron for classification, practical applications require complex architectures like transformers and ResNets that process multiple inputs through various hidden layers to produce outputs. Manually calculating and updating individual weights becomes impractical at this scale. PyTorch provides a structured approach through its neural network modules, enabling efficient implementation of sophisticated architectures.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/860/0*USeS0rqcvEQiAYsC"></figure> <p><em>Source: </em><a href="https://github.com/rasbt/LLMs-from-scratch/tree/main" rel="external nofollow noopener" target="_blank"><em>LLMs from Scratch</em></a></p> <h4>Introduction to torch.nn.Module</h4> <p>The torch.nn.Module serves as PyTorch's foundational class for neural networks, providing a systematic way to define and manage model architectures, parameters, and computations. This base class handles essential functionalities including parameter management, device placement, and training behaviors.</p> <p>The subclass has the following components:</p> <ul> <li>__init__: We define the layers of neural networks in the constructor of the subclass defined and how the layers interact during forward propagation.</li> <li>forward: The forward method describes how the input data passes through the network and comes together as a computation graph.</li> </ul> <h4>Creating Custom Neural Network Architectures</h4> <p>Complex neural networks require multiple layers with specific activation functions. Here’s a practical implementation of a multi-layer neural network:</p> <pre>class DeepNetwork(nn.Module):<br>    def __init__(self, num_inputs, num_outputs):<br>        super().__init__()<br>        <br>        self.layers = nn.Sequential(<br>            nn.Linear(num_inputs, 30),     # First hidden layer<br>            nn.ReLU(),                     # Activation function<br>            nn.Linear(30, 20),             # Second hidden layer<br>            nn.ReLU(),                     <br>            nn.Linear(20, num_outputs)      # Output layer<br>        )<br><br>    def forward(self, x):<br>        return self.layers(x)</pre> <p>nn.Sequential provides a container for stacking layers in a specific order, streamlining the forward pass implementation.</p> <h4>Model Parameters and Initialization</h4> <p>PyTorch automatically handles parameter initialization, but you can access and modify parameters:</p> <pre>model = DeepNetwork(50, 3)<br><br># Count trainable parameters<br>num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)<br>print(f"Trainable parameters: {num_params}")<br><br># Access layer parameters<br>for name, param in model.named_parameters():<br>    print(f"Layer: {name} | Size: {param.size()}")<br><br># Custom initialization<br>def init_weights(m):<br>    if isinstance(m, nn.Linear):<br>        torch.nn.init.xavier_uniform_(m.weight)<br>        m.bias.data.fill_(0.01)<br><br>model.apply(init_weights)</pre> <p>Each parameter for which requires_grad=True counts as a trainable parameter and will be updated during training. In the above code, this referes to the weights initialized in torch.nn.Linear layers.</p> <h4>Forward Propagation Implementation</h4> <p>Forward propagation defines how input data flows through the network. Let’s initialise random values and pass it through the model.</p> <pre># Sample forward pass<br>model = DeepNetwork(50, 3)<br>batch_size = 32<br>input_features = torch.randn(batch_size, 50)<br><br>with torch.no_grad():<br>    outputs = model(input_features)<br><br>print(f"Output shape: {outputs.shape}")</pre> <h4>Training Mode vs. Evaluation Mode</h4> <p>PyTorch models have distinct training and evaluation modes that affect certain layers’ behavior:</p> <pre>model = DeepNetwork(50, 3)<br><br># Training mode<br>model.train()<br>training_output = model(input_features)  <br># Layers like Dropout and BatchNorm active<br>print(training_output)<br><br># Evaluation mode<br>model.eval()<br>with torch.no_grad():<br>    eval_output = model(input_features)  # Deterministic behavior<br>    print(eval_output)</pre> <p>PyTorch models operate in two distinct modes:</p> <ol><li>Training Mode (model.train()):</li></ol> <ul> <li>Activates Dropout and BatchNorm layers</li> <li>Enables gradient computation and tracking</li> <li>Maintains computational graph for backpropagation</li> </ul> <p>2. Evaluation Mode (model.eval() with torch.no_grad()):</p> <ul> <li>Disables Dropout and freezes BatchNorm statistics</li> <li>Prevents gradient computation and tracking</li> <li>Optimizes memory usage by eliminating gradient storage</li> <li>Reduces computational overhead during inference</li> </ul> <p>This mode management ensures efficient resource utilization while maintaining appropriate model behavior for both training and inference phases.</p> <h3>Efficient Data Handling</h3> <p>Efficient data handling is crucial for developing robust deep learning models. PyTorch provides two primary tools for data management: the Dataset and DataLoader classes.</p> <h4>1. Dataset and DataLoader Overview</h4> <p>PyTorch’s data handling framework consists of</p> <ul> <li>Dataset: Defines data access and preprocessing</li> <li>DataLoader: Handles batch creation, shuffling, and parallel loading</li> </ul> <p>Let’s implement a simple classification dataset to demonstrate these concepts:</p> <pre>import torch<br>from torch.utils.data import Dataset, DataLoader<br><br># Training classification data<br>X_train = torch.tensor([<br>    [-1.2, 3.1],<br>    [-0.9, 2.9],<br>    [-0.5, 2.6],<br>    [2.3, -1.1],<br>    [2.7, -1.5]<br>])<br><br>y_train = torch.tensor([0, 0, 0, 1, 1])<br><br># Testing dataset<br>X_test = torch.tensor([<br>    [-0.8, 2.8],<br>    [2.6, -1.6],<br>])<br><br>y_test = torch.tensor([0, 1])</pre> <h4>2. Creating Custom Dataset Objects</h4> <p>Next, we create a custom dataset class, SampleDataset, by subclassing from PyTorch’s Dataset parent class. It has following properties:</p> <ul> <li>__init__: Initialize dataset attributes.</li> <li>__getitem__: Define data access for individual samples</li> <li>__len__: Return total number of samples</li> </ul> <pre>from torch.utils.data import Dataset<br><br>class SampleDataset(Dataset):<br>    def __init__(self, X, y):<br>    """Initialize the dataset with features and labels"""<br>        self.features = X<br>        self.labels = y<br>    def __getitem__(self, index):<br>    """Retrieve a single example and its label"""     <br>        one_x = self.features[index]     <br>        one_y = self.labels[index]       <br>        return one_x, one_y              <br>    def __len__(self):<br>    """Get the total number of examples in the dataset"""<br>        return self.labels.shape[0]     <br><br>train_ds = SampleDataset(X_train, y_train)<br>test_ds = SampleDataset(X_test, y_test)</pre> <h4>3. Implementing DataLoader</h4> <p>DataLoaders handle the heavy lifting of batching, shuffling, and parallel data loading. Now we can create DataLoaders from the SampleDataset object created. This can be done as follows:</p> <pre># Create DataLoader with specific configurations<br>train_loader = DataLoader(<br>    dataset=train_ds,     # Dataset Instance<br>    batch_size=2,         # Number of samples per batch<br>    shuffle=True,         # Shuffle the training data<br>    num_workers=0         # Number of parallel workers<br>    drop_last=True.       # Drop incomplete batch<br>)<br><br>test_loader = DataLoader(<br>    dataset=test_ds,<br>    batch_size=2,<br>    shuffle=False,        # No need to shuffle test data<br>    num_workers=0<br>)</pre> <p>Some key parameters of Dataloaders class are as follows:</p> <ul> <li>dataset: The Dataset instance to load data from</li> <li>batch_size: Number of samples per batch</li> <li>shuffle: Whether to shuffle data between epochs</li> <li>num_workers: Number of subprocesses for data loading</li> <li>drop_last: Whether to drop the last incomplete batch</li> <li>pin_memory: Pin memory for faster data transfer to GPU</li> </ul> <h4>Complete Example with Best Practices (Best Practice)</h4> <p>Here’s a comprehensive implementation incorporating all concepts:</p> <pre>import torch<br>from torch.utils.data import Dataset, DataLoader<br><br>class SampleDataset(Dataset):<br>    def __init__(self, X, y, transform=None):<br>        self.features = X<br>        self.labels = y<br>        self.transform = transform # Input transformations if required<br>    <br>    def __getitem__(self, index):<br>        x = self.features[index]<br>        y = self.labels[index]<br>        <br>        if self.transform:<br>            x = self.transform(x)<br>            <br>        return x, y<br>    <br>    def __len__(self):<br>        return len(self.labels)<br><br># Configuration for optimal performance<br>def create_data_loader(dataset, batch_size, is_training=True):<br>    return DataLoader(<br>        dataset=dataset,<br>        batch_size=batch_size,<br>        shuffle=is_training,<br>        num_workers=4 if is_training else 2,<br>        pin_memory=torch.cuda.is_available(),<br>        drop_last=is_training,<br>        persistent_workers=True<br>    )<br><br><br># Usage example<br>if __name__ == "__main__":<br>    # Create dataset<br>    dataset = SampleDataset(X_train, y_train)<br>    <br>    # Create data loader<br>    train_loader = create_data_loader(<br>        dataset=dataset,<br>        batch_size=32,<br>        is_training=True<br>    )<br>    <br>    # Training loop example<br>    for epoch in range(num_epochs):<br>        for batch_idx, (features, labels) in enumerate(train_loader):<br>            # Training operations here<br>            pass</pre> <p>This implementation provides a robust foundation for handling data in PyTorch, incorporating best practices for memory management and parallel processing. Adjust the configurations based on your specific use case and available computational resources.</p> <h3>Implementing Training Loops in PyTorch</h3> <p>A PyTorch training loop consists of several key components:</p> <ul> <li>model initialization,</li> <li>optimizer configuration,</li> <li>loss function definition, and</li> <li>the iterative training process.</li> </ul> <p>Here’s a structured implementation showcasing these elements.</p> <h4>Basic Training Loop Structure (Best Practice)</h4> <pre>import torch<br>import torch.nn as nn<br>from torch.optim import Adam<br>from torch.utils.data import DataLoader<br><br>def train_model(<br>    model: nn.Module,<br>    train_loader: DataLoader,<br>    val_loader: DataLoader,<br>    num_epochs: int,<br>    learning_rate: float,<br>    device: str = 'cuda' if torch.cuda.is_available() else 'cpu'<br>) -&gt; dict:<br>    """<br>    Trains a PyTorch neural network model using the provided data loaders.<br>    <br>    This function implements a standard training loop with validation after each epoch.<br>    It supports both CPU and GPU training and tracks various metrics during training.<br>    <br>    Args:<br>        model (nn.Module): The PyTorch model to train<br>        train_loader (DataLoader): DataLoader for training data<br>        val_loader (DataLoader): DataLoader for validation data<br>        num_epochs (int): Number of training epochs<br>        learning_rate (float): Learning rate for the optimizer<br>        device (str): Device to train on ('cuda' or 'cpu'), defaults to GPU if available<br>        <br>    Returns:<br>        dict: Training history containing:<br>            - train_loss: List of training losses per epoch<br>            - val_loss: List of validation losses per epoch<br>            - val_accuracy: List of validation accuracies per epoch<br>    """<br>    <br>    # Initialize Adam optimizer and Cross Entropy Loss criterion<br>    optimizer = Adam(model.parameters(), lr=learning_rate)<br>    criterion = nn.CrossEntropyLoss()<br>    <br>    # Move model to appropriate device (GPU/CPU)<br>    model = model.to(device)<br>    <br>    # Dictionary to store training metrics<br>    history = {<br>        'train_loss': [],<br>        'val_loss': [],<br>        'val_accuracy': []<br>    }<br>    <br>    # Main training loop over epochs<br>    for epoch in range(num_epochs):<br>        # Set model to training mode (enables dropout, batch norm, etc.)<br>        model.train()<br>        train_loss = 0.0<br>        <br>        # Iterate over training batches<br>        for batch_idx, (features, labels) in enumerate(train_loader):<br>            # Transfer batch data to appropriate device<br>            features = features.to(device)<br>            labels = labels.to(device)<br>            <br>            # Forward propagation<br>            outputs = model(features)<br>            loss = criterion(outputs, labels)<br>            <br>            # Backward propagation and optimization<br>            optimizer.zero_grad()  # Clear previous gradients<br>            loss.backward()        # Compute gradients<br>            optimizer.step()       # Update model parameters<br>            <br>            # Accumulate batch loss<br>            train_loss += loss.item()<br>            <br>            # Print progress every 100 batches<br>            if batch_idx % 100 == 0:<br>                print(f'Epoch: {epoch+1}/{num_epochs} | '<br>                      f'Batch: {batch_idx}/{len(train_loader)} | '<br>                      f'Loss: {loss.item():.4f}')<br>        <br>        # Calculate average training loss for the epoch<br>        train_loss = train_loss / len(train_loader)<br>        history['train_loss'].append(train_loss)<br>        <br>        # Validation phase<br>        model.eval()  # Set model to evaluation mode<br>        val_loss = 0.0<br>        correct = 0<br>        total = 0<br>        <br>        # Disable gradient computation for validation<br>        with torch.no_grad():<br>            for features, labels in val_loader:<br>                features = features.to(device)<br>                labels = labels.to(device)<br>                <br>                # Forward pass only<br>                outputs = model(features)<br>                loss = criterion(outputs, labels)<br>                <br>                # Accumulate validation metrics<br>                val_loss += loss.item()<br>                _, predicted = torch.max(outputs.data, 1)  # Get predicted class<br>                total += labels.size(0)                    # Count total samples<br>                correct += (predicted == labels).sum().item()  # Count correct predictions<br>        <br>        # Calculate validation metrics<br>        val_loss = val_loss / len(val_loader)<br>        val_accuracy = 100 * correct / total<br>        <br>        # Store validation metrics<br>        history['val_loss'].append(val_loss)<br>        history['val_accuracy'].append(val_accuracy)<br>        <br>        # Print epoch summary<br>        print(f'Epoch: {epoch+1}/{num_epochs} | '<br>              f'Train Loss: {train_loss:.4f} | '<br>              f'Val Loss: {val_loss:.4f} | '<br>              f'Val Accuracy: {val_accuracy:.2f}%')<br>    <br>    return history<br><br><br># Example Usage<br>def main():<br>    """<br>    Example implementation of the training pipeline.<br>    <br>    This function demonstrates how to use the train_model function<br>    with a custom model and configuration.<br>    """<br>    # Initialize model (assumed to be defined elsewhere)<br>    model = DeepNetwork()<br>    <br>    # Define training hyperparameters<br>    config = {<br>        'num_epochs': 10,     # Number of training epochs<br>        'learning_rate': 0.001,  # Learning rate for optimization<br>    }<br>    <br>    # Train the model with specified configuration<br>    history = train_model(<br>        model=model,<br>        train_loader=train_loader,  # Assumed to be defined elsewhere<br>        val_loader=test_loader,     # Assumed to be defined elsewhere<br>        num_epochs=config['num_epochs'],<br>        learning_rate=config['learning_rate']<br>    )</pre> <p>The training loop does the following gradient descent as following:</p> <ul> <li>The training process involves passing logits to the cross_entropy loss function, which internally applies softmax for optimized performance and numerical stability.</li> <li>The loss.backward() call computes gradients through PyTorch's computational graph</li> <li>The optimizer.step() step updates the model parameters using these gradients</li> <li>The optimizer.zero_grad() must be called every training iteration to reset gradients, preventing unintended accumulation that could distort the optimization process.</li> </ul> <h3>Model Persistence in PyTorch: Saving and Loading</h3> <p>PyTorch provides efficient mechanisms for model persistence through its state dictionary system. The state dictionary (state_dict) maintains a mapping between layer identifiers and their corresponding parameters (weights and biases).</p> <h3>Basic Model Persistence</h3> <h4>Saving Models</h4> <p>After training the model, it is necessary to save the model weights to reuse later for further training or deployment. Save a model’s learned parameters using the state dictionary:</p> <pre>import torch<br><br># Save model parameters<br>torch.save(model.state_dict(), "model_parameters.pth")</pre> <h4>Loading Models</h4> <p>The torch.load("model_parameters.pth") function reads the file "model_parameters.pth" and reconstructs the Python dictionary object containing the model’s parameters while model.load_state_dict() applies these parameters to the model, effectively restoring its learned state from when we saved it.</p> <p>We need the instance of the model in memory to apply the saved parameters. Here, the NeuralNetwork(2, 2) architecture needs to match the original saved model exactly.</p> <pre># Initialize model architecture<br>model = NeuralNetwork(num_inputs=2, num_outputs=2)<br><br># Load saved parameters<br>model.load_state_dict(torch.load("model_parameters.pth"))</pre> <h3>Comprehensive Model Persistence (Best Practice)</h3> <p>For production scenarios, save additional information alongside model parameters:</p> <pre># Save complete model state<br>checkpoint = {<br>    'model_state_dict': model.state_dict(),<br>    'optimizer_state_dict': optimizer.state_dict(),<br>    'epoch': epoch,<br>    'loss': loss,<br>    'model_config': {<br>        'num_inputs': 2,<br>        'num_outputs': 2<br>    }<br>}<br>torch.save(checkpoint, "model_checkpoint.pth")<br><br><br># Load complete model state<br>checkpoint = torch.load("model_checkpoint.pth")<br>model = NeuralNetwork(**checkpoint['model_config'])<br>model.load_state_dict(checkpoint['model_state_dict'])<br>optimizer.load_state_dict(checkpoint['optimizer_state_dict'])<br>epoch = checkpoint['epoch']<br>loss = checkpoint['loss']</pre> <h3>Conclusion</h3> <p>PyTorch’s architecture provides a robust foundation for deep learning development through its integrated components: tensor computations, automatic differentiation, and neural network modules. The framework’s design enables efficient model implementation through dynamic computation graphs, GPU acceleration, and intuitive APIs for data processing and model construction.</p> <p>For continued learning and implementation guidance, refer to PyTorch’s official documentation which provides comprehensive updates on best practices, optimizations, and emerging capabilities. This ensures your deep learning applications remain aligned with current framework standards and performance benchmarks.</p> <p>Want more AI/ML deep dives? Subscribe <a href="https://neuraforge.substack.com" rel="external nofollow noopener" target="_blank">here</a>.</p> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=06b66a651f1f" width="1" height="1" alt=""></p> </body></html>